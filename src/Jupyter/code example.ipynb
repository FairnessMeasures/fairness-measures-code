{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_structure'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-02b2bfbb19b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute_measures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistical_tests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_structure'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "from data_structure.dataset import Dataset\n",
    "from measures.absolute_measures import *\n",
    "from measures.statistical_tests import *\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.__data\n",
    "\n",
    "\n",
    "    @property\n",
    "    def protected_cols(self):\n",
    "        return self.__protected_cols\n",
    "\n",
    "\n",
    "    @property\n",
    "    def target_cols(self):\n",
    "        return self.__target_cols\n",
    "\n",
    "\n",
    "    def __init__(self, data):\n",
    "        if isinstance(data, str):\n",
    "            # expect data to be a filename, engine=python enables auto-detection of separator\n",
    "            self.__data = pd.read_csv(data, header=0, sep=None, engine='python')\n",
    "        elif isinstance(data, pd.DataFrame):\n",
    "            self.__data = data\n",
    "\n",
    "        self.__protected_cols = [col for col in self.__data.columns if col.startswith('protected')]\n",
    "        self.__target_cols = [col for col in self.__data.columns if col.startswith('target')]\n",
    "\n",
    "        # check if dataset is well-formed\n",
    "        if not self.__protected_cols:\n",
    "            raise ValueError(\"The dataset should contain at least one column that describes a protection status\")\n",
    "        if not self.__target_cols:\n",
    "            raise ValueError(\"The dataset should contain at least one column that describes a target variable\")\n",
    "\n",
    "        # check that protected attributes are indicated by integers\n",
    "        for protected_column in self.__protected_cols:\n",
    "            column_values = self.__data[protected_column]\n",
    "            protection_categories = column_values.unique()\n",
    "            if not all(isinstance(item, integer) for item in protection_categories):\n",
    "                raise ValueError(\"Protection status should be indicated by integers only\")\n",
    "\n",
    "\n",
    "    def normalize_column(self, column_name):\n",
    "        mean_col = self.data[column_name].dropna().mean()\n",
    "        min_col = self.data[column_name].dropna().min()\n",
    "        max_col = self.data[column_name].dropna().max()\n",
    "        self.data[column_name] = self.data[column_name].apply(lambda x: (x - mean_col) / (max_col - min_col))\n",
    "\n",
    "\n",
    "    def count_classification_and_category(self, target_col, protected_col, group, accepted):\n",
    "        \"\"\"\n",
    "        counts the number of items that have the desired combination of protection status and\n",
    "        classification result.\n",
    "        Example: group=0 and accepted=0 returns the number of non-protected that where classified negative\n",
    "\n",
    "        @param target_col:      name of the column in data that contains the classification results\n",
    "        @param protected_col:   name of the column in data that contains the protection status\n",
    "        @param group:           defines which protection status should be counted\n",
    "        @param accepted:        defines which classification result should be counted\n",
    "\n",
    "        @return: the number of occurrences of the given protection/classification combination\n",
    "        0 either if the given group group does not exist or is not classified into the\n",
    "        given class\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # get all classification results for given group group\n",
    "        classes_for_protected = self.get_all_targets_of_group(target_col, protected_col, group)\n",
    "        # count those that match given acceptance state\n",
    "        return (classes_for_protected == accepted).sum()\n",
    "\n",
    "\n",
    "    def get_all_targets_of_group(self, target_col, protected_col, group):\n",
    "        \"\"\"\n",
    "        returns a vector with all target variables out of a given target column for a given group\n",
    "\n",
    "        @param target_col:      name of the column in data that contains the classification results\n",
    "        @param protected_col:   name of the column in data that contains the protection status\n",
    "        @param group:           defines which group (grouped by protection status) should be considered\n",
    "\n",
    "        @return: array with target values\n",
    "        \"\"\"\n",
    "        return self.data.loc[self.data[protected_col] == group, target_col].values\n",
    "\n",
    "\n",
    "    def prob_positive_classification(self, target_col):\n",
    "        \"\"\"\n",
    "        @return: portion of items that have been classified positively\n",
    "        \"\"\"\n",
    "\n",
    "        value_counts = self.data[target_col].value_counts()\n",
    "        pos_counts = value_counts.get(1, default=0)\n",
    "\n",
    "        return pos_counts / len(self.data[target_col])\n",
    "\n",
    "\n",
    "\n",
    "    def conditional_prob_for_group_category(self, target_col, protected_col, accepted):\n",
    "        \"\"\"\n",
    "        calculates the conditional probability for each group (protected and favored) to be classified\n",
    "        as positive (if accepted=1) or negative respectively (if accepted=0).\n",
    "        Assumes that classification results are binary, either positive or negative\n",
    "\n",
    "        @param target_col:      name of the column in data that contains the classification results\n",
    "        @param protected_col:   name of the column in data that contains the protection status\n",
    "        @param accepted:        int that says if the conditional probability of being accepted should be\n",
    "                                calculated or the one of being rejected\n",
    "\n",
    "        @return: a dictionary with protection status as key and conditional probability as value\n",
    "\n",
    "        \"\"\"\n",
    "        if target_col not in self.target_cols:\n",
    "            raise ValueError(\"given target column doesn't exist\")\n",
    "\n",
    "        if protected_col not in self.protected_cols:\n",
    "            raise ValueError(\"given protected column doesn't exist\")\n",
    "\n",
    "        conditional_probs = {}\n",
    "        unique, counts = np.unique(self.data[protected_col], return_counts=True)\n",
    "        protected_group_counts = dict(zip(unique, counts))\n",
    "\n",
    "        # calculate conditional probability of positive outcome given each group category\n",
    "        for group_category, member_count in protected_group_counts.items():\n",
    "\n",
    "            conditional_probs[group_category] = \\\n",
    "                self.count_classification_and_category(target_col, protected_col, group_category, accepted) / member_count\n",
    "\n",
    "        return conditional_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute Measures  \n",
    "## Mean Difference  \n",
    "\n",
    "$$d = E(y^+) \\mid s^0) - E(y^+ \\mid s^1)$$\n",
    "\n",
    "takes a dataset with columns that contain target values (i.e. prediction scores of the model) as well as protection status variables and calculates the mean difference of the targets of each protected group to the non-protected group. For each target column, first the variables areordered into a subset for each protected group and the mean is calculated. Then the values\n",
    "of the target column for the non-protected group are extracted and their mean is calculated.  \n",
    "\n",
    "Each protected mean of predictions is subtracted from the non-protected mean.\n",
    "`dataset`: data that contains all target and protected variables\n",
    "`target_column`: name of the column that contains the prediction values\n",
    "`protected_column`: name of the column that contains the protection status\n",
    "`non-protected`: the value within protected_column that describes the non-protected category zero on default\n",
    "\n",
    "`return`: a python dataframe that contains the target as column name and the protection categories from protected_column as indices. Note that the non-protected category is excluded as it would contain only zeros anyway. The cells contain the values of the mean differences between the non-protected group and the particular protected one for that particular target variables.\n",
    "If the difference greater zero, the mean of the non-protected group was greater than the mean of the protected one, otherwise smaller.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_difference(dataset, target_column, protected_column, non_protected=0):\n",
    "    if protected_column not in dataset.protected_cols:\n",
    "        raise ValueError(\"given protected column name doesn't exist in dataset. Check spelling.\")\n",
    "\n",
    "    if target_column not in dataset.target_cols:\n",
    "        raise ValueError(\"given target column name doesn't exist in dataset. Check spelling.\")\n",
    "\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    # get all protected attribute categories\n",
    "    group_categories = dataset.data[protected_column].unique()\n",
    "\n",
    "    # calculate mean of target values for the non-protected group\n",
    "    target_values_nonprotected = dataset.data.loc[dataset.data[protected_column] == non_protected, target_column]\n",
    "    mean_nonprotected = np.mean(target_values_nonprotected)\n",
    "\n",
    "    # calculate mean of target values for all protected categories\n",
    "    for category in group_categories:\n",
    "        if category == non_protected:\n",
    "            # skip non_protected category, has been done above\n",
    "            continue\n",
    "        else:\n",
    "            target_values_protected = dataset.data.loc[dataset.data[protected_column] == category, target_column]\n",
    "            mean = np.mean(target_values_protected)\n",
    "            mean_diff = mean_nonprotected - mean\n",
    "            df = pd.DataFrame({target_column: [mean_diff]}, index=[category])\n",
    "            result = result.append(df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Difference\n",
    "\n",
    "- calculates the difference between the probability of being accepted given being a favored group member and the probability of being accepted given being a protected group member. This difference is normalized by the ratio of all accepted candidates by all favored candidates.  \n",
    "- Non-Discrimination is indicated when no difference in these probabilities exist. Maximum discrimination is indicated when the result is 1 (or -1 respectively), i.e. the probability of being accepted as a favored is 1 whereas it is 0 for a protected group member.\n",
    "\n",
    "- Only works for the binary case -> one protected group, one non-protected group, classification result is either positive or negative\n",
    "\n",
    "- Assumes that in the dataset the favored group is labeled with protection status 0, protected group with 1\n",
    "\n",
    "- Assumes that in the dataset the positive outcome is labeled as 1, negative as 0\n",
    "\n",
    "`protected_col`: name of the column that contains the protection status\n",
    "`target_col`: name of the column that contains the classifier results\n",
    "\n",
    "`return`:  \n",
    "\t- 0    if the probability of being accepted is equal for all groups  \n",
    "        - > 0   if the probability of being accepted is higher for the non-protected group  \n",
    "        - < 0   if the probability of being accepted is higher for the protected group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_difference(dataset, target_col, protected_col):\n",
    "\n",
    "    unique_prot, counts_prot = np.unique(dataset.data[protected_col], return_counts=True)\n",
    "    unique_targ, counts = np.unique(dataset.data[target_col], return_counts=True)\n",
    "\n",
    "    if len(unique_prot) > 2 or len(unique_targ) > 2:\n",
    "        print(\"This function is only applicable for binary problems. See function docs for details.\")\n",
    "        return np.nan\n",
    "\n",
    "    protected_group_counts = dict(zip(unique_prot, counts_prot))\n",
    "    conditional_probs = dataset.conditional_prob_for_group_category(target_col, protected_col, 1)\n",
    "\n",
    "    counts_pos = (dataset.data[target_col] == 1).sum()\n",
    "    counts_neg = (dataset.data[target_col] == 0).sum()\n",
    "    outcome_counts = {0:counts_neg, 1:counts_pos}\n",
    "\n",
    "    prob_pos = outcome_counts[1] / len(dataset.data.index)\n",
    "    prob_neg = outcome_counts[0] / len(dataset.data.index)\n",
    "    prob_prot = protected_group_counts[1] / len(dataset.data.index)\n",
    "    prob_fav = protected_group_counts[0] / len(dataset.data.index)\n",
    "\n",
    "    d_max = min((prob_pos / prob_fav), (prob_neg / prob_prot))\n",
    "\n",
    "    if d_max == 0:\n",
    "        raise ZeroDivisionError\n",
    "\n",
    "    delta = (conditional_probs[0] - conditional_probs[1]) / d_max\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'demo.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-62639481eb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=========== difference of means test ============='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_test_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'protected_sex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "dataset = Dataset(filename)\n",
    "print('=========== difference of means test =============')\n",
    "print(t_test_ind(dataset, 'target_score', 'protected_sex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n=========== mean differences ==============')\n",
    "print(mean_difference(dataset, 'target_score', 'protected_sex').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n=========== normalized differences ============')\n",
    "    print(normalized_difference(dataset, 'target_loan_approved', 'protected_sex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n=========== impact ratio ============')\n",
    "    print(impact_ratio(dataset, 'target_loan_approved', 'protected_sex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n=========== odds ratio ============')\n",
    "    print(fisher_exact_two_groups(dataset, 'target_loan_approved', 'protected_sex'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}